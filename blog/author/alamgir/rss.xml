<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>https://alamgirm.github.io/blog</title>
   
   <link>https://alamgirm.github.io</link>
   <description>Programming, Automation, Data Science, Machine Learning, Visualizations, Arduino, Raspberry Pi and other IoT.</description>
   <language>en_GB</language>
   <managingEditor> alamgir</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Continuous Integration and Continuous Development on AWS : part III - Ansible</title>
	  <link>/blog//Continuous-Integration-and-Continuous-Deployment-using-AWS-part-III</link>
	  <author>alamgir</author>
	  <pubDate>2017-12-16T15:18:00-05:00</pubDate>
	  <guid>/blog//Continuous-Integration-and-Continuous-Deployment-using-AWS-part-III</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/17_12_16/cicd-0.png" alt="CICD" class="leftimg" />
DevOps philosophy has it that an application is better developed, tested and deployed in small pieces, in a continuous manner. This hopefully serves the changing requirements (of the clients or users) in both time and cost effective way. The developers, and operational team also always have something that is proved to be working, something to roll back to in case a change does not end successfully. To practically embrace the philosphy there needs to be an organizational pipeline where the teams (development, QA testing, deployment, monitoring etc) participate. And for better communication among the teams, most if not all teams use same kind of automation tools/platforms. This post is the first in a series of posts that talks about automation tools, employed on Amazon AWS cloud platform.</p>

<!--more-->

<ol>
  <li>loginto the Ansible Controller instance</li>
  <li>
    <p>Update packages and install pip (that will install ansible). For RH epel needs to be installed first</p>

    <pre>
- Sudo to root: $ sudo su
- Update the OS:# yum -y update
- Install wget: # yum -y install wget
- Download epel repo: # wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
- Install epel repo: # yum -y install epel-release-latest-7.noarch.rpm 
</pre>
  </li>
</ol>

<p>Now the pip installer</p>

<pre>
   - Install pip: # yum -y install python-pip
   - Install ansible: # pip install ansible
   </pre>

<ol>
  <li>
    <p>Install git client</p>

    <pre>
# yum -y install git
</pre>
  </li>
  <li>
    <p>Copy the private key file <code class="highlighter-rouge">HostForAnsibleKey.pem</code> into the home directory.
The controller node need this key to access the host.</p>
  </li>
  <li>
    <p>Manually create an inventory of all the resources. Store it as <code class="highlighter-rouge">/etc/ansible/hosts</code></p>

    <pre>
[test-servers]
 10.179.44.7
</pre>
  </li>
</ol>

<p>[ Alternatively I could use the ec2.py script to list]</p>

<ol>
  <li>Configure ansible. Create a file named <code class="highlighter-rouge">ansible.cfg</code> inside folder <code class="highlighter-rouge">ansible</code>.</li>
</ol>

<pre>
[defaults]
inventory     = /etc/ansible/hosts
remote_user   = ec2-user
become        = True
become_method = sudo
become_user   = root
nocows        = 1
</pre>

<ol>
  <li>Check and see if ansible can access the host.</li>
</ol>

<pre>
ansible -m ping 'test-servers' --private-key ../HostForAnsibleKey.pem
</pre>

<p>If it works fine, the result should be:</p>

<pre>
10.179.44.7 | SUCCESS =&gt; {
    "changed": false, 
    "ping": "pong"
}
</pre>

<h3 id="creating-an-ansible-playbook">Creating an ansible playbook</h3>

<h3 id="creating-helloworld-app">Creating HelloWorld app</h3>
<ol>
  <li>inside ansible folder, create a new folder named roles.</li>
  <li><code class="highlighter-rouge">ansible-galaxy init nodejs</code> creates a new role nodejs
 We’ll use this role to install nodejs on to the target system</li>
  <li>Go inside nodejs, then tasks and edit file main.yml</li>
</ol>
<pre>
---
# tasks file for nodejs

- name: Installing nodejs and npm
  yum:
    name: ""
    enablerepo: epel
    state: installed
  with_items:
    - nodejs
    - npm
</pre>
<p>Whenever ansible runs, it will check the existence of these package, if not found will install.</p>

<ol>
  <li>Another role is needed to install and run the app. Go back to roles folder, and issue
<code class="highlighter-rouge">ansible-galaxy init helloworld</code>. After the role creattion go inside, helloworld and then files.</li>
  <li>This folders contains files that ansible can upload to the target. Lets get 2 files from web (ideally we’d get them from github)</li>
</ol>
<pre>
wget http://bit.ly/2vESNuc -O files/helloworld.js
</pre>
<ol>
  <li>Now go inside the task folder (under helloworld) and edit main.yml file</li>
</ol>
<pre>
- name: Copying the application files
  copy:
    src: helloworld.js
    dest: /home/ec2-user/
    owner: ec2-user
    group: ec2-user
    mode: 0644
  notify: restart helloworld

- name: Copying the upstart file
  copy:
     src: helloworld.conf
     dest: /etc/init/helloworld.conf
     owner: root
     group: root
     mode: 0644

- name: Starting the HelloWorld nodejs service
  service:
      name: helloworld
      state: started
</pre>

<p>Now need to add a handler. Head to folder handlers under helloworld. Edit main.yml</p>
<pre>
- name: restart helloworld
  service:
      name: helloworld
      state: restarted
</pre>

<p>Module dependency. The app needs node4j to run. Open meta/main.yml
At the bottom, remove [] and make it appear</p>
<pre>
dependencies:
   - pre_req
   - nodejs
</pre>

<h3 id="main-playbook-file">Main Playbook file</h3>
<p>Here is the main playbook file</p>
<pre>
---
- hosts: test_servers
  become: yes
  roles:
     - helloworld
</pre>

<p>Now play the playbook file:
<code class="highlighter-rouge">ansible-playbook helloworld.yml --private-key ../HostForAnsibleKey.pem</code></p>

	  ]]></description>
	</item>

	<item>
	  <title>Continuous Integration and Continuous Deployment on AWS : part II - CloudFormation</title>
	  <link>/blog//Continuous-Integration-and-Continuous-Deployment-using-AWS-part-II</link>
	  <author>alamgir</author>
	  <pubDate>2017-12-16T15:18:00-05:00</pubDate>
	  <guid>/blog//Continuous-Integration-and-Continuous-Deployment-using-AWS-part-II</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/17_12_16/cicd-0.png" alt="CICD" class="leftimg" />
In the <a href="Continuous-Integration-and-Continuous-Development-using-AWS-part-I.html"> last post</a> we created a limited-rights IAM user that we’ll use in this post and in future posts to create different infrastructure resources on AWS Cloud. We can defintely use the account to login into AWS Management Console, and create and manage resources, but that would be too tedious for not-too-small project, and more importatnly against the philosohpy of DevOps. In DevOps philosophy we’d like to automate everything, including creating infrastrure using code. In this post, we’ll see how we can create few EC2 intances, create SSH key pairs, and Security Group to controll access to the EC2 instances- all using code. We’ll login into the AWS Management Console to verify that everything is created as expected.</p>

<!--more-->

<h3 id="aws-cli">AWS CLI</h3>
<p>To access AWS services programmatically we need to install a piece of software from Amazon, AWS CLI. AWS CLI is written in Python, and is available as a Python package. Depending on the operating system, the instructions for downloading and installing AWS CLI is different. But for Linux/MacOSX users, the process is straight-forward:</p>
<pre>
$ sudo pip install awscli
</pre>

<p>Once installed, we can use the tool to interact with the AWS. For example, the command</p>
<pre>
$ aws ec2 describe-instances
</pre>
<p>will fetch a list of all instances. However, for this command to succedd, we have to configure AWS-CLI with the IAM user we created. The configuration is done using the command <code class="highlighter-rouge">$ aws configure</code>, and then providing the AWS Access key ID and AWS Secret Access key. These two pieces of information are found in the credential file we downloaded and copied in our <code class="highlighter-rouge">DevOps</code> folder. There are two other optional information to provide: default region and default output format. The region is the Amazon geographic region we want to use by default, and the output format is the format of information we’d like AWS to provide us in return when we exectue an <code class="highlighter-rouge">aws</code> command.</p>

<p>To verify if the user is good to go, we can issue the command: <code class="highlighter-rouge">$ aws ec2 describe-instances</code>. It should come back with a list of EC2 instances I might have in that default region.</p>

<h3 id="creating-ssh-key-pairs">Creating SSH Key Pairs</h3>
<p>We’ll need to create two EC2 instances, that we’ll use down the way for ansible. Before creating any EC2 instances, we’ll have to create keys for SSH access to these nodes password-free. Creating a key pair is easy, just issue <code class="highlighter-rouge">$ aws ec2 create-key-pair</code> and provide a name for the key. The <strong>important</strong> thing is however noting the private key created. We <strong>must</strong> copy (using mouse to select) the private key and save into our own desktop/laptop for further use. The following commands crate the keys we need. I called them:
<code class="highlighter-rouge">AnsibleControllerKey</code> and <code class="highlighter-rouge">HostForAnsibleKey</code>.</p>
<pre>
$ aws ec2 create-key-pair --key-name AnsibleControllerKey
$ aws ec2 create-key-pair --key-name HostForAnsibleKey
</pre>

<p>One nuisence in copying and pasting the private key is the <code class="highlighter-rouge">\n</code> character. The console adds them for readability
but we must remove them in the file. I saved the keys with names: <code class="highlighter-rouge">AnsibleControllerKey.pem</code> and <code class="highlighter-rouge">HostForAnsibleKey.pem</code>, in the <code class="highlighter-rouge">DevOps</code> folder. I also must make them non-readable to other users (Unix permission 400) using the command <code class="highlighter-rouge">chmod 400 AnsibleControllerKey.pem</code> and  <code class="highlighter-rouge">chmod 400 HostForAnsibleKey.pem</code></p>

<p>Though we have interacted with the AWS cloud directly using the AWS CLI command terminal, this is only suitable for small number of items. If we had to create a say one hundred key pairs, we would have never done that manually. In that case, someone would write a script, either shell or Python.</p>

<h3 id="creating-infrasture-using-codes">Creating Infrasture using Codes</h3>
<p>AWS <code class="highlighter-rouge">CloudFormation</code> service facilitates automated creation and management of infrastructure. The architectural configuration of the desired infrastructure is specified in either JSON or YAML format. From that configuration, CloudFormation can create the whole infrastructure, initialize OS, help install package etc so that the environment is ready to run an application. In technical term, the configuration settings are called a <em>stack</em>, and AWS offers predefined <em>stack template</em> for stacks for many common purposes. In addition, it offers a simple GUI based template builder/editor called CloudFormtion designer. There is a second tool called CloudFormer that can trawl through the instances etc already created in the AWS, and build a template based on these. And offcourse, it is possible to build a template from scratch.</p>

<h4 id="creating-stack-template-using-troposhpere">Creating Stack Template using Troposhpere</h4>
<p>To programmatically create a stack template, Python has a package <code class="highlighter-rouge">troposphere</code> available. To install:</p>
<pre>
$ sudo pip install troposphere
</pre>

<p>We then write the following script that will help us generate a stack template:</p>
<pre>
"""Generating CloudFormation template"""
from ipaddress import ip_network
from ipify import get_ip
from troposphere import (Base64, ec2, GetAtt, Join, Output, Parameter, Ref, Template)

ApplicationPort = "3000"

sgAnsible = ec2.SecurityGroup("SecurityGroup1", GroupDescription="SG for ansible controller",
    SecurityGroupIngress=[
        ec2.SecurityGroupRule(
            IpProtocol="tcp",
            FromPort="22",
            ToPort="22",
            CidrIp="0.0.0.0/0"
        )
    ]
)

instanceAnsibleController = ec2.Instance("AnsibleController", ImageId="ami-c998b6b2", 
    InstanceType="t1.micro", SecurityGroups=[Ref(sgAnsible)], 
    KeyName='AnsibleControllerKey')


sgHost = ec2.SecurityGroup("SecurityGroup2", GroupDescription="SG for host",
    SecurityGroupIngress=[
        ec2.SecurityGroupRule(
            IpProtocol="tcp",
            FromPort="22",
            ToPort="22",
            CidrIp="172.33.0.0/16"
        ),
        ec2.SecurityGroupRule(
            IpProtocol="tcp",
            FromPort=ApplicationPort,
            ToPort=ApplicationPort,
            CidrIp="0.0.0.0/0"
        )
    ]
)


instanceHostForAnsible = ec2.Instance("HostForAnsible", ImageId="ami-c998b6b2", 
    InstanceType="t1.micro", SecurityGroups=[Ref(sgHost)], 
    KeyName='HostForAnsibleKey')


t = Template()
t.add_description("CloudFormation Template")

t.add_resource(sgAnsible)
t.add_resource(sgHost)
t.add_resource(instanceAnsibleController)
t.add_resource(instanceHostForAnsible)

t.add_output(Output(
    "Instance1PublicIp",
    Description="Public Ip of our ansible controller instance.",
    Value=GetAtt("AnsibleController", "PublicIp")
))

t.add_output(Output(
    "Instance2PublicIp",
    Description="Public Ip of our host instance.",
    Value=GetAtt("HostForAnsible", "PublicIp")
))


print(t.to_json())
</pre>

<p>The code above contains statements to create two appropriate security groups, and then two EC2 instances. For the instance <code class="highlighter-rouge">AnsibleController</code> we allowed only SSH on port 22 from anywhere. Howeve, the actual application host node <code class="highlighter-rouge">instanceHostForAnsible</code> allows SSH on port 22 only from the controller host. It however allows tcp traffic on port 3000, that our application will serve.</p>

<p>We save the Python script as <code class="highlighter-rouge">cf-template.py</code> and then run from the termnial <code class="highlighter-rouge">$python cf-terminal.py</code>. It should spash out some JSON. Redirecting the output <code class="highlighter-rouge">$python cf-template.py &gt; cf-template.tpl</code> gives the template file that we are going to use with CloudFormation.</p>

<p>Once we have the template file, we log into the Maganagement Console, and select <code class="highlighter-rouge">CloudFormation</code> service. Click on <code class="highlighter-rouge">Create Stack</code>, then choose <code class="highlighter-rouge">Upload a template to Amazon S3</code> and select our template file. Clicking Next and then giving the stack a name takes to Options page. One more click on next button brings a summary of the template. Hitting the Create button starts craeting the EC2 instances, and the security group related to them.</p>

<p>To verify, we go to the EC2 dashboard and click on Instances:
 <img src="assets/images/2017/17_12_17/ec2-instances.png" alt="EC2 instances" class="leftimg" /></p>

<p>We can also verify the security groups if wished.</p>

<p>Few things to remember:</p>

<ul>
  <li>The image ID for EC2, amazon machine image (AMI) instances are not the same for different region. It has be the one that we are creating our EC2 instances on. The best way to look for the <code class="highlighter-rouge">ami</code> in trying to launch an EC2 manually from the management console.</li>
  <li><code class="highlighter-rouge">CloudFormation</code> does not (or can not) use existing security groups. The SGs need to be created along with the EC2 from the same stack template.</li>
</ul>

<p>In next post, I’ll install ansible and setup a small automated build and deployment system.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Continuous Integration and Continuous Deployment on AWS : part I - setup IAM</title>
	  <link>/blog//Continuous-Integration-and-Continuous-Development-using-AWS-part-I</link>
	  <author>alamgir</author>
	  <pubDate>2017-12-16T15:18:00-05:00</pubDate>
	  <guid>/blog//Continuous-Integration-and-Continuous-Development-using-AWS-part-I</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/17_12_16/cicd-0.png" alt="CICD" class="leftimg" />
DevOps philosophy has it that an application is better developed, tested and deployed in small pieces, in a continuous manner. This hopefully serves the changing requirements (of the clients or users) in both time and cost effective way. The developers, and operational team also always have something that is proved to be working, something to roll back to in case a change does not end successfully. To practically embrace the philosphy there needs to be an organizational pipeline where the teams (development, QA testing, deployment, monitoring etc) participate. And for better communication among the teams, most if not all teams use same kind of automation tools/platforms. This post is the first in a series of posts that talks about automation tools, employed on Amazon AWS cloud platform.</p>

<!--more-->

<h3 id="aws-setup">AWS Setup</h3>
<p>The first thing someone should do is to create an IAM user, and not use the root or main AWS account. It is straightforward- login to your AWS root account at: console.aws.amazon.com
<img src="assets/images/2017/17_12_16/aws-root-login.png" alt="AWS Root login" class="leftimg" />
If you have multi-factor authentication (MFA) enabled, a second screen will be appearing asking for authentication code. After successful login appears the AWS dashboard that lists many of the services AWS offers. A searchbox is readily available to quickly navigate to a service. We need the IAM service. Clicking on IAM will take to the IAM dashboard:
<img src="assets/images/2017/17_12_16/iam-dashboard.png" alt="IAM dashboard" class="leftimg" /></p>

<p>We need to create a new user (with limited priviledges) for all the exercises related to DevOps tools. Click on <code class="highlighter-rouge">Users</code> on the left pane, then <code class="highlighter-rouge">Add User</code> on the top to initiate the user creation process.
<img src="assets/images/2017/17_12_16/iam-add-user.png" alt="IAM Add User" class="leftimg" /></p>

<p>I am using <code class="highlighter-rouge">DevOpUser</code> as user name, and checking both <em>Programmatic</em> and <em>AWS Management Console</em> access check boxes. I am letting AWS autogenerate a password, but not forcing the user to reset the password.  Hitting <em>Next</em> will take us to permissions.</p>

<p>On Permissions screen, I am choosing the <em>Attach existing policies directly</em> option. Typing EC2 in the search box, I choose <code class="highlighter-rouge">EC2FullAceess</code> and <code class="highlighter-rouge">S3FullAccess</code>. Then follw next to finally create the user. I click on <strong>Download.csv</strong> button to save the login credentials for  newly created user <code class="highlighter-rouge">DevOpUser</code>. Also take note of the login url:
<code class="highlighter-rouge">https://xxxxxx.signin.aws.amazon.com/console</code> (xxxxxx denotes string I removed for privacy).
<img src="assets/images/2017/17_12_16/iam-add-user-done.png" alt="IAM Add User" class="leftimg" /></p>

<p>To keep things organized on my own local machine (a MacBook), I created a folder named <code class="highlighter-rouge">DevOps</code> under my home directory. The whole patch should be <code class="highlighter-rouge">/Users/&lt;username&gt;/DevOps</code>. I copy the credential file downloaded in the last step into this directory.</p>

<h3 id="more-aws-setup">More AWS Setup</h3>
<p>The user created above has full priviledge in using EC2 service. However, we need one more priviledge: access to <code class="highlighter-rouge">CloudFormation</code> so that we can create a set of EC2 instances from code, in an automated way. We go back to IAM service dashboard and click on <code class="highlighter-rouge">Users</code> on the left panel, then select the user <code class="highlighter-rouge">DevOpUser</code>. It should show a summary of the user, and a button at the bottom to add <code class="highlighter-rouge">inline policy</code>. I clicked on <code class="highlighter-rouge">Add inline policy</code> then chose <code class="highlighter-rouge">Custom Policy</code>, then finally pasted this piece of code in the editor:</p>
<pre>
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "cloudformation:Describe*",
                "cloudformation:List*",
                "cloudformation:Get*",
                "cloudformation:Create*",
                "cloudformation:Delete*",
                "cloudformation:Update*",
                "cloudformation:Validate*"
            ],
            "Resource": "*"
        }
    ]
}
</pre>

<p>I named the policy as <code class="highlighter-rouge">CloudFormationFullAccess</code>, then validated the policy before applying. Though validation should be enough, however if you want to be abolutely sure, there is an easy way to simulate the policies attached to the user. This simulation allows us to find out if the user has enough priviledges to do things it needs to. The simulator found at <a href="https://policysim.aws.amazon.com"> Amazon site </a>.</p>

<h3 id="testing-new-user">Testing new User</h3>
<p>The login url for (non-root) limited-rights user is different.  You shoul be able to see it immediately after creating the user. Generally it has the following format:</p>
<pre>
https://Root_Account_ID.signin.aws.amazon.com/console/
</pre>
<p>Where <code class="highlighter-rouge">Root_Accound_ID</code> is the either the account number or alias of the root account. Visiting the login link, and after providing the user name and password for <code class="highlighter-rouge">DevOpUser</code> I found this dashboard.
<img src="assets/images/2017/17_12_16/iam-user-dashboard.png" alt="User Dashboard" class="leftimg" />
This dashboard allows creating and managing AWS services. In addition to this dashboard, AWS allows creating and managing service resouces via programmatic access. In the next post we’ll see how to create EC2 instances
using AWS CLI (command line  interface).</p>


	  ]]></description>
	</item>

	<item>
	  <title>Continuous Integration and Continuous Development on AWS : part I - setup IAM</title>
	  <link>/blog//Continuous-Integration-and-Continuous-Deployment-using-AWS-part-I</link>
	  <author>alamgir</author>
	  <pubDate>2017-12-16T15:18:00-05:00</pubDate>
	  <guid>/blog//Continuous-Integration-and-Continuous-Deployment-using-AWS-part-I</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/17_12_16/cicd-0.png" alt="CICD" class="leftimg" />
DevOps philosophy has it that an application is better developed, tested and deployed in small pieces, in a continuous manner. This hopefully serves the changing requirements (of the clients or users) in both time and cost effective way. The developers, and operational team also always have something that is proved to be working, something to roll back to in case a change does not end successfully. To practically embrace the philosphy there needs to be an organizational pipeline where the teams (development, QA testing, deployment, monitoring etc) participate. And for better communication among the teams, most if not all teams use same kind of automation tools/platforms. This post is the first in a series of posts that talks about automation tools, employed on Amazon AWS cloud platform.</p>

<!--more-->

<h3 id="aws-setup">AWS Setup</h3>
<p>The first thing someone should do is to create an IAM user, and not use the root or main AWS account. It is straightforward- login to your AWS root account at: console.aws.amazon.com
<img src="assets/images/2017/17_12_16/aws-root-login.png" alt="AWS Root login" class="leftimg" />
If you have multi-factor authentication (MFA) enabled, a second screen will be appearing asking for authentication code. After successful login appears the AWS dashboard that lists many of the services AWS offers. A searchbox is readily available to quickly navigate to a service. We need the IAM service. Clicking on IAM will take to the IAM dashboard:
<img src="assets/images/2017/17_12_16/iam-dashboard.png" alt="IAM dashboard" class="leftimg" /></p>

<p>We need to create a new user (with limited priviledges) for all the exercises related to DevOps tools. Click on <code class="highlighter-rouge">Users</code> on the left pane, then <code class="highlighter-rouge">Add User</code> on the top to initiate the user creation process.
<img src="assets/images/2017/17_12_16/iam-add-user.png" alt="IAM Add User" class="leftimg" /></p>

<p>I am using <code class="highlighter-rouge">DevOpUser</code> as user name, and checking both <em>Programmatic</em> and <em>AWS Management Console</em> access check boxes. I am letting AWS autogenerate a password, but not forcing the user to reset the password.  Hitting <em>Next</em> will take us to permissions.</p>

<p>On Permissions screen, I am choosing the <em>Attach existing policies directly</em> option. Typing EC2 in the search box, I choose <code class="highlighter-rouge">EC2FullAceess</code> and <code class="highlighter-rouge">S3FullAccess</code>. Then follw next to finally create the user. I click on <strong>Download.csv</strong> button to save the login credentials for  newly created user <code class="highlighter-rouge">DevOpUser</code>. Also take note of the login url:
<code class="highlighter-rouge">https://xxxxxx.signin.aws.amazon.com/console</code> (xxxxxx denotes string I removed for privacy).
<img src="assets/images/2017/17_12_16/iam-add-user-done.png" alt="IAM Add User" class="leftimg" /></p>

<p>To keep things organized on my own local machine (a MacBook), I created a folder named <code class="highlighter-rouge">DevOps</code> under my home directory. The whole patch should be <code class="highlighter-rouge">/Users/&lt;username&gt;/DevOps</code>. I copy the credential file downloaded in the last step into this directory.</p>

<h3 id="more-aws-setup">More AWS Setup</h3>
<p>The user created above has full priviledge in using EC2 service. However, we need one more priviledge: access to <code class="highlighter-rouge">CloudFormation</code> so that we can create a set of EC2 instances from code, in an automated way. We go back to IAM service dashboard and click on <code class="highlighter-rouge">Users</code> on the left panel, then select the user <code class="highlighter-rouge">DevOpUser</code>. It should show a summary of the user, and a button at the bottom to add <code class="highlighter-rouge">inline policy</code>. I clicked on <code class="highlighter-rouge">Add inline policy</code> then chose <code class="highlighter-rouge">Custom Policy</code>, then finally pasted this piece of code in the editor:</p>
<pre>
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "cloudformation:Describe*",
                "cloudformation:List*",
                "cloudformation:Get*",
                "cloudformation:Create*",
                "cloudformation:Delete*",
                "cloudformation:Update*",
                "cloudformation:Validate*"
            ],
            "Resource": "*"
        }
    ]
}
</pre>

<p>I named the policy as <code class="highlighter-rouge">CloudFormationFullAccess</code>, then validated the policy before applying. Though validation should be enough, however if you want to be abolutely sure, there is an easy way to simulate the policies attached to the user. This simulation allows us to find out if the user has enough priviledges to do things it needs to. The simulator found at <a href="https://policysim.aws.amazon.com"> Amazon site </a>.</p>

<h3 id="testing-new-user">Testing new User</h3>
<p>The login url for (non-root) limited-rights user is different.  You shoul be able to see it immediately after creating the user. Generally it has the following format:</p>
<pre>
https://Root_Account_ID.signin.aws.amazon.com/console/
</pre>
<p>Where <code class="highlighter-rouge">Root_Accound_ID</code> is the either the account number or alias of the root account. Visiting the login link, and after providing the user name and password for <code class="highlighter-rouge">DevOpUser</code> I found this dashboard.
<img src="assets/images/2017/17_12_16/iam-user-dashboard.png" alt="User Dashboard" class="leftimg" />
This dashboard allows creating and managing AWS services. In addition to this dashboard, AWS allows creating and managing service resouces via programmatic access. In the next post we’ll see how to create EC2 instances
using AWS CLI (command line  interface).</p>


	  ]]></description>
	</item>

	<item>
	  <title>Barebone AVR Programming - LED Blinker</title>
	  <link>/blog//Barebone-AVR-Programming-LED-Blinker</link>
	  <author>alamgir</author>
	  <pubDate>2017-08-09T16:18:00-04:00</pubDate>
	  <guid>/blog//Barebone-AVR-Programming-LED-Blinker</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/2017_08_09_AVR_board.png" alt="AVR Board" class="leftimg" />
Arduino is fun and easy, and it gives the best introducton to AVR processors. However, if you want to build something useful, you’ll soon hit the wall. Arduinio has a huge collection of shields, and supporting libraries for them, but developing a well-designed system is difficult when it comes to debugging. This is due to the fact that Arduino IDE hides most of the intricacies of AVR MCU. If you are used to debug program using breakpoints, stepping and tracing through lines of code, the Arduino IDE is no help. The AVR Studio development environment from Atmel is the saviour here. However, it can’t connect to an Arduino board through the USB port. Fortunately, most Arduino boards have a special header called ICE (in-circuit-emulator), which is actually an SPI (serial peripheral interface) connector. A special hardware tool, for example AVR ISP MK II is needed to connect. There are other alternatives too.
<!--more--></p>

<h3 id="avr-dev-board">AVR dev-board</h3>
<p>An alternative to Arduino board is to use a development board. Retailer websites like <a href="http://aliexpress.com">Aliexpress</a> have good ranges of development boards with Atmel processors. In this post, I have used the board found <a href="https://www.aliexpress.com/item/1PCS-DC-5V-ATmega128-AVR-Core-Development-Board-Minimum-System-Module-ISP-JTAG/32745789402.html">here</a>. The board uses an ATMega128 chip, has both JTAG and ISP connectors, could be powered by external power supply or from the JTAG. There is an on-board toggle switch to change power supply source. the As an addedd bonus the board has two LEDs connected to bits 0 and 1 of port A. This is quite useful for testing the board. If desired the LEDs can be disconnected by taking the jumper (next to LEDs) off.</p>

<h3 id="programmer-device">Programmer device</h3>
<p>You might know that the Arduino IDE uploads program (compiled sketches) to an Ardiuno board using serial port (emulated over the USB). Under the hood there is also a small program, already put into the flash memory of the board during manufacturing, handles the receiving of program code from Arduino IDE and writes onto the flash memory. That piece of code is often called Arduino bootloader (not in tradional meaning of booting off course). The actuall uploading of program is handled by a software tool called <code class="highlighter-rouge">avrdude</code>. It is possible to use <code class="highlighter-rouge">avrdude</code> to manually upload program as long as the <code class="highlighter-rouge">MCU</code> has the bootlaoder installed. For the dev-board I am using, there is no bootloader, so we need either a JTAG or ICE hardware tool. Such tools don’t need any helper other than the MCU itself. For the porpose of this post, I used a JTAG programmer tool. The JTAG programmer/debugger I used is bought from <a href="https://www.aliexpress.com/item/Free-shipping-AVR-USB-Emulator-debugger-programmer-JTAG-ICE-for-Atmel/623898152.html">Aliexpress</a>. 
<img src="assets/images/2017/2017_08_09_JTAG_programmer.png" alt="JTAG debugger programmer" /></p>

<h3 id="programming-setup">Programming setup</h3>
<p>I’ll write a simple test program in C language to check the dev-board. The best way of doing this (for programmers with deskop programming background) is to use the IDE provided by Atmel. For this post I used AVR Studio version 4.18. Though the latest version is 7, for beginners to keep things under control version 4 is just adequate.</p>

<p>So, if you are following to do the same, download and install AVR Studio (it only runs on Windows). The installer also installs the USB driver software required to use the JTAG programmer.</p>

<p>If everything goes smooth, run AVR Studio and select a new project. Provide a name and location for the project, and select Project type: <code class="highlighter-rouge">AVR GCC</code>. Hitting Next will bring the Degug/programming platform, choose JTAG ICE (or the suitable one based on your programmer), and the MCU type. The board I am using has an ATMega128.</p>

<p>I named the project TestBoard, the wizard created the project and an empty file named TestBoard.c.
Following is the code I typed in into TestBoard.c file.</p>

<pre>
	//
	//	File name: TestBoard.c
	//	Purpose: Alternately blinks the two LEDs connected 
	//           at Port A bit 0 and bit 1.
	//
	
	#define F_CPU 1000000

	#include &lt;avr/io.h&gt;
	#include &lt;util/delay.h&gt;

	int main (void)
	{
		// all bits in Port A are set as Output
		DDRA = 0xFF;
		// send out all zeros to turn OFF the LEDs
		PORTA = 0x00;

		while(1) {

			// LED on PA.0 is ON, PA.1 is OFF
			PORTA = 0x01; // binary 0000 0001 

			_delay_ms(1000); // delay 1 sec
	
			// LED on PA.0 is OFF, PA.1 is ON
			PORTA = 0x02; // binary 0000 0010
	
			_delay_ms(1000); // delay 1 sec	
		}

	return 0;
	}
	
</pre>

<h3 id="explanation">Explanation</h3>
<p>The C program code first defines the processor clock frequncy via <code class="highlighter-rouge">F_CPU</code>. This is required for the delay functions used in the program. The program first initializes Port A as all output, and sends zero to the port A. This turns the LEDs off (if they were ON before). Then we enter a loop where we first write 1 to first LED and 0 to second LED. After a second delay, we write 0 to first LED and 1 to the second LED. Then again a second of delay. This gives an impression of alternate flushing LEDs.</p>

<h3 id="output">Output</h3>
<p>A short clip showing the LEDs <a href="assets/images/2017/2017_08_09_LED_Blinking.3gp">blinking</a>.</p>

<h3 id="links-to-software-and-hardware">Links to software and hardware</h3>

<ul>
  <li>The <a href="https://www.aliexpress.com/item/1PCS-DC-5V-ATmega128-AVR-Core-Development-Board-Minimum-System-Module-ISP-JTAG/32745789402.html">development board</a>.</li>
  <li>JTAG <a href="https://www.aliexpress.com/item/Free-shipping-AVR-USB-Emulator-debugger-programmer-JTAG-ICE-for-Atmel/623898152.html">debugger/programmer</a>.</li>
  <li>Atmel <a href="http://www.atmel.com/tools/studioarchive.aspx">AVR Studio</a>. Scroll down for 4.18.</li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Serial Communications- How to</title>
	  <link>/blog//serial-communication-how-to</link>
	  <author>alamgir</author>
	  <pubDate>2017-07-08T09:18:00-04:00</pubDate>
	  <guid>/blog//serial-communication-how-to</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/2017_07_08_RS232.png" alt="RS232" class="leftimg" /> Digital systems need to communicate, even devices within a single system need to communicate with each other. In hardware, this means exachanges of digital signals between two parties. Since data are represented as binary numbers in a digital system, transferring of a binary number can happen in two manners: all the bits in one go (in parallel) or one bit at a time (in serial). This gives rise to design of two types of communication system: parallel and serial. The first thing to note is parallel communication needs more wires but supposedly transfer data in relatively faster manner. In contrast, serial communication can work with fewer wires, but would take longer to transfer the same amount of data. From this, it might look that parallel communication is ‘better’ than serial one, but in reality this is hardly the case.</p>

<!--more-->

<h2 id="role-of-clock-synchronous-vs-asyncrhonous">Role of Clock: synchronous vs asyncrhonous</h2>
<p>When two parties communicate, it is very important that they are on the same page, i.e, the receiver understands what the sender is sending. In Digital communication, at the hardwire level, the reciver must know when a bit starts, how long is the duration etc. One very common way to keep both the parties in synch is to use a series of rectangular pulse, known as clcok signal, clock pulse, or simply clock. Generally the sender party is responsible for sending the clock and the receiver gets in synch to it, before trying to detect the data. This is syncrhonous communication. While this sounds good, there are more problems with sending clock: they get smeared over distance, and suffer from jitter. The problems are sometimes so bad, that it is now very common not use any separete clock at all. Rather, the data signal itself has built-in clock signal. In this case, the reciever runs its own clock, but aligns it when a wave of data comes in. This is asynchrounous communication.</p>

<h3 id="line-coding-of-data">Line-coding of Data</h3>
<p>We know data are represented in Binary in digital systems, and often a bianry 1 means HIGH voltage (3.3V or 5V) and 0 means LOW voltage (0V). However, it is not uncommon to use a <em>negative voltgate to indicate 1</em>. In addition,  when we send these data over a communication line, there is one more thing: the duration of each bit. The receiver must know how long a bit lasts. Bits are sent one after another without any gap in between, so the receiver must also know when it is to start, when it should stop.</p>

<p>In one particluar instance (RS232- see later) of serial communication, few bits of Binary data are sent as a frame. A frame is a single unit, the receive either receives it fully as good or discards it. The start of frame is indicated by a LOW pulse, followed by the data bits. A parity bit is then added for error checking, followed by one or two stop bits (HIGH) indicating the end of frame. The duration of each data bit, (inversion of which called baud rate), number of data bits, type of parity and number of stop bits- these are all configurable parameters. The hardwire chip (often called UART chip)  expects these parameters before a transmission could begin. UART chips are dumb in the sense that they do not have the capability to negotiate the parameters with other party, it depends on the programmer to set the parameters.
<img src="assets/images/2017/2017_07_08_linecoding.png" alt="RS232 Line coding" /></p>

<p>This little picture needs some explanation. The start bit is ALWAYS low, it designates the start of the frame. So as the UART on the receiving end while monitoring its RX line, can start to detect data bits the moment RX goes LOW. The next few pulses can be HIGH or LOW or a mixture, depedning on exactly what the data bits are. This is the greay area in the picture. To help check with error detection the sender party may add an extra parity bit. It could be either LOW or HIGH depending on the party type in use, or even omitted if no parity is used. This decision is made by the developer, when configuring the UARTs. Finally the stop bit(s) are always HIGH, the red area in the picure. The duration can be double of the start bit if two stop bits are required.</p>

<h3 id="rs232">RS232</h3>
<p>RS232 is a very old stadard of serial communication, long before modern day PCs have come. It evolved over time, came down to 9-pin from original 25-pin connector, and now even bare 3-pin/line communication is quite common.  At this bare minimum, we have a TX (transmit), RX (receive), and a GND (ground) line. TX and RX are crossed bewtween the devies that communicate, so that either of the device can send data to another. Data can flow full-duplex, meaning both parties can send/recieve simultaneously (as they use different physical lines).</p>

<p>In embedded development a serial link (not exactly an RS232) is often used to either program a board or connect a serial display terminal. Recent PCs dont have any RS232 port any more, so a USB to Serial converter is used. The original RS232 stipulated a +3V to +15V for representing a Binary 0 and -3V to -15V for a Binary 1. For the serial communication on embedded boards, and popular IoT baords, the voltage level is reversed and reduced. A Binary 0 is often 0V and a Binary 1, is either 3.3V or 5V. This is <em>opposite</em> of what the RS232 standard uses. To avoid confusion, some people refer to this as <em>TTL Serial</em>. It is to remember that the start bit is still a LOW pulse, and the stop bit(s) is HIGH.</p>

<p>The baud rate is standardized to any of 1200, 2400, 4800, 9600, 19200, 38400, 57600, and 115200. The rate 9600 is the most common, some using 115200 for short cable. The <em>TTL Serial</em> adheres to the same standard baud rates.</p>

<h3 id="configuration-example">Configuration Example</h3>
<p>If we want the baud rate of 9600, 8-bits of data, no parity, and just one stop bit, then each frame would have 10-bits. The extra two bits (start and stop) are overhead, but we have to use them to make the communication happen.</p>

<h4 id="terminal-emulator">Terminal Emulator</h4>
<p>Finally there is a software tool that can emulate a serial terminal. This when connected to an embedded board helps us to see what is going on. On Linux platforms <code class="highlighter-rouge">picocom</code> and <code class="highlighter-rouge">minicom</code> are two popular serial terminal emulator. Again, before they could display something meaningful, they need to be configured with correct baud rate, data bits, parity and stop bits.</p>

<h3 id="common-mistakes">Common Mistakes</h3>

<ul>
  <li>The configuration parameters: baud rate, data length, parity and stop bit must be set at the <em>BOTH</em> end of the link. Both the UART must have the same parameters to make the communication workable.</li>
  <li>The TX and RX lines <em>MUST</em> be crossed- othewise there is no chance of communication.</li>
  <li>Some boards are powered by 3.3V supply, and cant withstand any voltage higher than that. Make sure the USB to Serial converter does not have 5V in such case.</li>
  <li>Serial communication is point-to-point or party to party. It can have more than two devices. If more than 2 devices are connected on the same wires, it wont work.</li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Basics of block storage devices</title>
	  <link>/blog//basics-of-block-storage-device</link>
	  <author>alamgir</author>
	  <pubDate>2017-06-23T02:18:00-04:00</pubDate>
	  <guid>/blog//basics-of-block-storage-device</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/2017_06_hard_disk.png" alt="Hard disk" class="leftimg" /> Today’s mass storage devices include magnetic hard disk, solid state drive, and often flash drive. Though technologically quite different, all these storage classes have one thing in common: they are accessed in a bigger chunk of data unit, not by a byte. This unit of access is called block (sometimes also called page). The internal technology, organizational structure etc could be whatever but the storage device’s adapter IDE/SATA/PATA/SCSI exposes the storage in a uniform manner to the operating system.</p>

<!--more-->

<h2 id="magnetic-hard-disks">Magnetic Hard Disks</h2>
<p>A magnetic hard disk, often simply hard disk drive, consists of  a set of metal circular platter put together in a spindle. A 2.5-inch drive now can have a maximum of 5 platters (max capacity 5TB), while a 3.5-inch drive can have 5 to 8 platers (max 12TB).  Read/Write heads are placed just a thin air away of the surfaces on each platter. Heads are numbered. Each surface of a platter is hypothetically considered to have circular tracks, each track split into sectors. Tracks are numbered too, begining at 0 from outside, increasing towards center. Physical size of sectors are bigger around the outer side of the platter, and gets smaller towards the centre. However, to keep things simple each sector is capable of storing equal amount of data, most commonly 512 bytes. (A newer standard called Advanced Format is calling for 4096 bytes).</p>

<p>Same numbered tracks on all the platters are imagined to form a cylinder. Therefore, to identify a particular track, one needs a cylinder number and head number. Once in the desired track, a sector is the smallest addressable unit identified by another number.  So to identify a sector uniquely in an entire disk, one needs the cylinder, head and sector (CHS) number.</p>

<p>Older PCs would access storage (both floppy and hard) using these CHS addressing. The PC BIOS interrupt 13hex allowed/served that. However, with the wider adoption of hard disks, and increasing storage capacity, CHS was found to be unncessarily complex and burdensome for the operating system (since it is the OS that manages the storage). Then came LBA.</p>

<h3 id="logical-block-addressing-lba">Logical Block Addressing (LBA)</h3>
<p>In LBA philosopy the entire stoarage is consindered as a linear array of blocks. Each blck is identified by a single block number. Once an address (block number) is given, the hard disk adapter maps that to physical C/H/S. This means LBA is independent of the internal organization of disk, and simply referes them as blocks (which for hard disks are sectors).</p>

<p>LBA address can be 32-bit, 48-bit or even 64-bit, and the addressing is simply linear: starts at zero and grows upward. Which address is mapped to which sector is up to the drive adapter. However, most drives follow a simple forumla. More can be found in <a href="https://en.wikipedia.org/wiki/Logical_block_addressing"> Wikipedia</a>.</p>

<h3 id="disk-partition">Disk Partition</h3>
<p>A physical disk drive can be logically divided into more than one unit and accessed as an independent storage, even by different operating system. There are mainly two schemes on PCs to do that: the legacy MBR (master boot record), and newer GPT (GUID Partition Table). Apple has its own scheme.</p>

<h4 id="master-boot-record-mbr">Master Boot Record (MBR)</h4>
<p>Ignoring the wording “boot record”, lets pretend “MBR” is a scheme to have multiple partitions in a single physical disk drive. The information about the partions (and more) are stored in the first (LBA=0) Block (also a sector for hard disk) of a drive. An “MBR” partitioning scheme can have a maximum of 4 partitions (all 4 primary or 3 primary and 1 extended which in turn can have more <code class="highlighter-rouge">logical partitions</code> within it).  The first primary partion, called <code class="highlighter-rouge">system partition</code> stores opeating system boot files. A layout of a disk with “MBR” scheme is shown below: <img src="assets/images/2017/2017_06_23_ms_mbr.gif" alt="MBR Scheme" title="MBR scheme" />
The first 440 bytes in the MBR that reads Master Boot Code in the picture is actually executable code. When a PC powers up, the BIOS, as part of the booting proceess, reads those codes and execute them.</p>

<p>Structure of different versions of “MBR” can be found in <a href="https://en.wikipedia.org/wiki/Master_boot_record"> Wikipedia MBR</a> enry.</p>

<h4 id="boot-sector">Boot Sector</h4>
<p>More than one primary partions can have a bootable operating system. The first sector on a partion is boot sector (if it has boot record). Similar to master boot code, boot sector can have executable code that the BIOS or a boot loader loads and executes. The boot sector is only valid for a partion, that is marked as <code class="highlighter-rouge">bootable</code> with a special signature.</p>

<h4 id="guid-partition-table-gpt">GUID Partition Table (GPT)</h4>
<p>Among the few limitations of “MBR” scheme, the partition table entries indicate the begining/ending of a partition as 32-bit LBA. This imposes a limitation of maximum 2TB disk capacity. GPT removes that restrictions, uses 64 bits for LBA, and supports upto 128 partitions. Though originally developed as part of EFI, GPT scheme however leaves the legacy LBA=0 <code class="highlighter-rouge">Protective MBR</code> untouched. An example of a GPT scheme is shown below: <img src="assets/images/2017/2017_06_23_gpt.png" /></p>

<h4 id="credits">Credits</h4>
<ul>
  <li>The hard disk picture is taken from <a href="http://ccm.net/contents/385-hard-drive"> CCM </a></li>
  <li>The “MBR” picture has been borrowed from  <a href="https://gerardnico.com/wiki/data_storage/partition"> here.</a></li>
  <li>MBR structure is taken from  <a href="https://upload.wikimedia.org/wikipedia/commons/0/07/GUID_Partition_Table_Scheme.svg">wikipedia</a></li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Inside ATMega AVR microcontroller</title>
	  <link>/blog//Inside-ATmega-AVR</link>
	  <author>alamgir</author>
	  <pubDate>2017-06-14T08:18:00-04:00</pubDate>
	  <guid>/blog//Inside-ATmega-AVR</guid>
	  <description><![CDATA[
	     <p><img src="assets/images/2017/17_06_14_ATmega328P.jpg" alt="Atmel ATmega328P" class="rightimg" />Atmel offers a wide variety of AVR MCU available in different series or families. MCU from these families differ in capabilities and funcionalities and sometimes in instructions available and architecture. However,  the design of AVR itself followes some common philosophy that could help us understand the internal architecture of such an MCU. In this post we talk about Atmel ATmega MCU which are available in different parts numbers, and with differnt amount of program memory.</p>

<!--more-->

<h2 id="internal-architecture-of-atmega-family">Internal Architecture of ATmega family</h2>
<p>Looking at the block diagram of internal architecture of ATmega family one would notice that the MPU has:</p>

<ul>
  <li>Serial I/O communication for dowanloading of program</li>
  <li>Flash memory for storing program to be executed</li>
  <li>EEPROM (for storing CPU configuration bits)</li>
  <li>Peripheral I/O</li>
  <li>Analog/Digital converter</li>
  <li>Timers/counters</li>
  <li>Data memory</li>
  <li>CPU core (ALU, Program counter, general purpose registers etc)</li>
</ul>

<p><img src="assets/images/2017/17_06_14_Atmel_ATmega_arch.png" alt="Atmel ATmega" title="Atmel ATmega MPU." /></p>

<p>AVR is based on modidfied Harvard architecture, so it is expected the program and data memory space tos be seperate. In addition to that, AVR allows readonly access to any data residing in the program memory, but no writes are allowed by the program itself. In addition to the memories for data and programs, AVR also has few bits of EEPROM for storing CPU configuration parameters (we’ll see later). When compared to a CPU like Intel 8080 or Zilog Z80, the ATmega has lots of other functionalities buil-it, to be justly called a microcontroller. Lets talk them in detail:</p>

<h4 id="serial-io">Serial I/O</h4>
<p>While Intel 8080 or Zilog Z80 needs a UART chip to communicate with the outside world via serial connection, ATmega has this functionality built right into the chip making serial communication trivial. Some chips offer USB commucations too.</p>

<h4 id="memories">Memories</h4>
<p>ATmega has flash memory for storing programs, and EEPROM for storing configuration parameters. Contents of both these memories are preserved when the power is off. Both these can be written from outside with appropriate tool. For storing temporary data there is data memory, which is in fact static RAM. The exact amount of thse memories vary depending on the model number.</p>

<h4 id="cpu">CPU</h4>
<p>The CPU core in AVR like most other CPU has ALU, Program Counter, and a host of general purspose registers. ATmega has 32 general purpose registers, each being 8-bit wide. The number and usage can slightly vary depending on the model. Surprisingly enough, these registers are mapped to first 32 bytes of the data memory. This meeans a program whishing to access the registers can simply read/wirte data to the specific memory locations. Last six of the 32 regisers are used as index registers, each in a 16-bit wide fashion. PC (program counter), a 14-bit special purpose register, points to the next executable instruction in <i>program memory</i>. When the MCU is first powered up, or reset, the PC is loaded to with value <code class="highlighter-rouge">0x0000</code> (this could be changed though). The SP (stack pointer) consists of two registers (taken from the total 32) and points to a memory location in <i>data memory</i>. In addition, AVR has few status regisers to reflect various operational status.</p>

<h4 id="peripheral-io">Peripheral I/O</h4>
<p>ATmega supports digital input/output of data with outside world, most likely from the same board. Some of these I/O can be analog, PWM (pulse width modulated) signals, others could be simple TTL (transistor transisto logic). Specilized communicatoin such as I2C, SPI, CAN bus can also be supported with proper support circuit and programs. Often there is an analog comparator that could be used for comparing analog signals. Digital data from/to outside world are stored in memory locations starting right after the 32 registers map. Though these locations are called I/O registers, they are not CPU registers, just ordinary memory locations mapped as an I/O port. Depending on model there could be 64 or more I/O registers.</p>

<h4 id="analogdigital-converter">Analog/Digital Converter</h4>
<p>ATmega has in-built A/D (Analog to Digital) converter. Some models have D/A (Digital to Analof) converter too. This allows interfacing with analog world without needing extranal A/D chips.</p>

<h4 id="timerscounters">Timers/Counters</h4>
<p>ATmega has on chip timers/counters, and thre are two kinds. The first kind is a 8-bit synchronous where the clock signal is derived from the CPU clock. The second kinds allows connecting an external clock circtuit to trigger the timer/counter and works independent of the CPU clock. Each of the timer/counter available can operate in a multiple of modes depending on application needs.
<img src="/assets/images/2017/17_06_14_Atmel_ATmega_arch2.png" alt="Atmel ATmega" title="Atmel ATmega MPU." /></p>

<h5 id="other-features">Other Features</h5>

<p>Depending on the model, certain models can have special sensors built-in, can have an LCD driver, LIN bus support etc.</p>

<h4 id="pin-configurations">Pin configurations</h4>
<p>An ATmega chip has many more functions than it has physical pins to support them for. To determine which functionalities are avalilable at which pins, ATmega has something called control register. Changing a suitable bit in the register can make a pin digital or analog, input or output, attach an intenal pull-up resistance etc. The timers/counters, communication interface, A/D etc can be configured by adjusting bits in the configuration control registers. The expectation with such design is that the user would configure the chip for his application need and the chip would just operate the way it is configured.</p>

<h4 id="watchdog-timer">Watchdog timer</h4>
<p>Though not shown in the picture, ATmega chips have a special timer, still programmable, called watchdog timer. This allows user programs or say an operating system to watch the MCU if it is stuck in a program execution. If that happens, a separate circuit can reset the MCU witout human intervention.</p>

<h4 id="credits">Credits</h4>
<ul>
  <li>The pictures in this article are courtesy of <a href="http://shop.oreilly.com/product/0636920037880.do">Arduino- A technical reference</a></li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Modern microcontroller: AVR series</title>
	  <link>/blog//modern-microcontroller-avr-group</link>
	  <author>alamgir</author>
	  <pubDate>2017-06-13T02:18:00-04:00</pubDate>
	  <guid>/blog//modern-microcontroller-avr-group</guid>
	  <description><![CDATA[
	     <p>The story of AVR familiies of microcontrollers (MCU), that power popular Arduino development boards began with two Norwegian students who designed a microcontroller as academic project. It was based on modified Harvard achitecture and RISC instructions set. The design later bought up by Atmel, and the two original designers continued to work on and improve. <img src="assets/images/2017/17_06_13_Atmel_AVR_logo.png" alt="AVR logo" class="rightimg" /> Atmel, understandly targetting the market of Intel 8051 releases the first AVR AT90S8515, a 8-bit MCU with same pin out as Intel 8051. Though originally 8-bit today AVR has 32-bit MCU, and offers multiple families of MCU with varied degree of capabilities and functionalities. There are however few common features: for example use of on-chip flash memory for program storage, EEPROM bits for CPU configuration flags etc. Within each family there are multiple MCUs available.</p>

<!--more-->

<h2 id="avr-families">AVR Families</h2>
<p>AVR MCUs are generally put into any of the following falimies:</p>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>TinyAVR</th>
      <th>MegaAVR</th>
      <th>XMEGA</th>
      <th>AVR32</th>
      <th>App Specific</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Data memory</td>
      <td>uptp 1024</td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Word size</td>
      <td>8-bit</td>
      <td>8-bit</td>
      <td>8-bit</td>
      <td>32-bit</td>
      <td>depends</td>
    </tr>
    <tr>
      <td>Program memory</td>
      <td>0.5 to 16KB</td>
      <td>4-256KB</td>
      <td>16-384KB</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Package</td>
      <td>6-32 pin</td>
      <td>28-100pin</td>
      <td>variable</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Peripheral</td>
      <td>limited</td>
      <td>extened</td>
      <td>extended</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Instrunctions</td>
      <td>Some limit</td>
      <td>Extened</td>
      <td>Extened</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>Extra feature</td>
      <td>No</td>
      <td>Option</td>
      <td>Option</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="specific-models">Specific Models</h2>
<p>Below are some specifuc models that are used often. The table is not complete, and accuracy is not guranteed.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Flash memory</th>
      <th>EEPROM</th>
      <th>SRAM</th>
      <th>Chip pins</th>
      <th>I/O pins</th>
      <th>Clock</th>
      <th>Feature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ATtiny13</td>
      <td>1K</td>
      <td>64</td>
      <td>160</td>
      <td>8</td>
      <td>6</td>
      <td>20MHz</td>
      <td> </td>
    </tr>
    <tr>
      <td>ATtiny85</td>
      <td>8K</td>
      <td>512</td>
      <td>512</td>
      <td>8</td>
      <td>6</td>
      <td>20MHz</td>
      <td> </td>
    </tr>
    <tr>
      <td>ATMega32</td>
      <td>32K</td>
      <td>1K</td>
      <td>2K</td>
      <td>40</td>
      <td>32</td>
      <td>16MHz</td>
      <td> </td>
    </tr>
    <tr>
      <td>ATmega32U4</td>
      <td>32K</td>
      <td> </td>
      <td> </td>
      <td>44</td>
      <td>26</td>
      <td>16MHz</td>
      <td>USB</td>
    </tr>
    <tr>
      <td>ATmega128</td>
      <td>128K</td>
      <td> </td>
      <td> </td>
      <td>64</td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>ATmega168</td>
      <td>16K</td>
      <td>512</td>
      <td>1K</td>
      <td>28/32</td>
      <td>23</td>
      <td>20MHz</td>
      <td> </td>
    </tr>
    <tr>
      <td>ATmega328</td>
      <td>32K</td>
      <td>1K</td>
      <td>2K</td>
      <td>28/32</td>
      <td>23</td>
      <td>20MHz</td>
      <td> </td>
    </tr>
    <tr>
      <td>ATmega649</td>
      <td>64K</td>
      <td> </td>
      <td> </td>
      <td>64</td>
      <td> </td>
      <td> </td>
      <td>LSB</td>
    </tr>
    <tr>
      <td>ATmega1280</td>
      <td>128K</td>
      <td> </td>
      <td> </td>
      <td>100</td>
      <td>86</td>
      <td>16MHz</td>
      <td> </td>
    </tr>
    <tr>
      <td>ATmega2560</td>
      <td>256K</td>
      <td> </td>
      <td> </td>
      <td>100</td>
      <td>86</td>
      <td>16MHz</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="more-details">More details</h3>

<p>More details about the features of various families can be found in <a href="http://www.atmel.com/products/microcontrollers/avr/default.aspx">Atmel’s web</a> site. Considering both the price and features, ATMega family is probably the best choice among IoT and hooby users. Choices and details about ATMega family chips are available <a href="http://www.atmel.com/products/microcontrollers/avr/megaavr.aspx"> here.</a></p>

	  ]]></description>
	</item>

	<item>
	  <title>Earliest Microprocessor: Zilog Z80</title>
	  <link>/blog//earlier-microprocessor-Zilog-Z80</link>
	  <author>alamgir</author>
	  <pubDate>2017-06-12T02:18:00-04:00</pubDate>
	  <guid>/blog//earlier-microprocessor-Zilog-Z80</guid>
	  <description><![CDATA[
	     <p>The CPU design team at Intel in the 70’s was led by <a href="https://en.wikipedia.org/wiki/Federico_Faggin">Federico Faggin</a>. After resigning from Intel Federico formed the start-up company Zilog, for design, development and marketing of microprocessor. <img src="assets/images/2017/17_06_12_Zilog_Z80.jpg" alt="Zilog Z80" class="rightimg" /> Zilog Z80 was their first product to hit the market, aimed for embedded applications. Its direct competitor was Intel 8080, and in fact Zilog always highligheted in commercials about its superiority over 8080. Compared to Intel 8080 which required +12V, -5V and +5V, Z80 needed only one +5V supply, had simple clock, and supported more registers, instructions, addressing modes, and even non-maskable interrupts.   Z80 was a gigantic success that helped the company grew from just elevel to a thousand employees in just two years. Many other semiconductor companies around the world copied the design of Z80 and sold their chips. Famaous Atari computuers, the first one to have color display were built on Zilog Z80.</p>

<!--more-->

<h2 id="zilog-z80">Zilog Z80</h2>
<p>Looking at the internal block diagram, Zilog Z80 has similar architecture as compared to Intel 8080, same 8-bit data bus and registers, and 16-bit address bus. What is surprising is the inclusion of two sets of general purpose registers. Namely, the registers <code class="highlighter-rouge">W, Z, B, C, D, E, H, L</code> can used in pairs to act like 16-bit as with 8080, but their contents can be saved by copying to a whole set of mirrored registers named <code class="highlighter-rouge">W', Z', B', C', D', E', H', L'</code>- and this could be done using just one EXX instruction. The accumulator <code class="highlighter-rouge">A</code> has also a friend <code class="highlighter-rouge">A'</code> also do the flags set <code class="highlighter-rouge">F</code> as <code class="highlighter-rouge">F'</code>. These primed registers could not be loaded directly, only could have swapped values with their counterparts. The special purpose registers are similar, bearing similar names too: PC (program counter), SP (stack pointer), IX and IY (both index registers). This feature of having two sets of registers make programming much easier when writing sub-routine or interrupt service.</p>

<p><img src="assets/images/2017/17_06_12_Zilog_Z80_arch.png" alt="Zilog 80" title="Zilog Z80 CPU architecture." /></p>

<p>Zilog Z80 supported maximum of 64KB memory, and additional 256 I/O ports each. Dymanic memories could be used without specilized refresh circuit as the CPU itself provides one.</p>

<p>Similar to Intel 8080, Zilog Z80 overlaps its fetching and executing cycle, meaning, while an instruction is being executed, the next instruction is fetched from memory if the bus is is not being used. Most of the instructions for Z80 are just one byte, but the longest one can be 4-byte long. The total number of instructions is also higher than Intel 8080.</p>

<h3 id="support-chips">Support Chips</h3>
<p>A full-blown system with Zilog Z80 could be built without needing much extra chips. However, many of the following chips that were originally designed to work with Intel 8080 work just fine with Zilog Z80.</p>

<ul>
  <li>8238 System controller and bus driver</li>
  <li>8251 UART (universal asynchronous/synchronous receiver/transmitter)</li>
  <li>8253 programmable interval timer/counter</li>
  <li>8255 programmable peripheral device</li>
  <li>8257 DMA (direct memory access) controller</li>
  <li>8259 interrupt controller</li>
</ul>

<h4 id="credits">Credits</h4>
<ul>
  <li>The Zilog Z80 image is courtesy of <a href="http://www.cpu-world.com/CPUs/Z80/">CPU-World.com</a></li>
  <li>The architecture image is borrowed from <a href="http://www.z80.info/z80arki.htm">Z80 Info</a></li>
</ul>

	  ]]></description>
	</item>


</channel>
</rss>
